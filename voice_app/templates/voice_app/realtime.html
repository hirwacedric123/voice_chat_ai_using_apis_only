<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>üéôÔ∏è Real-Time AI Voice Chat</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            color: #333;
        }

        .container {
            background: white;
            border-radius: 20px;
            padding: 40px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            text-align: center;
            max-width: 700px;
            width: 90%;
        }

        h1 {
            margin-bottom: 20px;
            color: #333;
            font-size: 2.5em;
        }

        .subtitle {
            color: #666;
            margin-bottom: 30px;
            font-size: 1.1em;
        }

        .voice-controls {
            margin: 30px 0;
            display: flex;
            justify-content: center;
            gap: 20px;
            align-items: center;
        }

        .record-btn {
            background: linear-gradient(135deg, #ff6b6b, #ee5a24);
            border: none;
            border-radius: 50%;
            width: 100px;
            height: 100px;
            font-size: 2em;
            color: white;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 10px 25px rgba(255, 107, 107, 0.3);
        }

        .record-btn:hover {
            transform: translateY(-3px);
            box-shadow: 0 15px 35px rgba(255, 107, 107, 0.4);
        }

        .record-btn.active {
            background: linear-gradient(135deg, #2ed573, #1e90ff);
            animation: pulse 1.5s infinite;
        }

        .interrupt-btn {
            background: linear-gradient(135deg, #ffa502, #ff6348);
            border: none;
            border-radius: 10px;
            padding: 15px 25px;
            color: white;
            cursor: pointer;
            font-size: 1em;
            transition: all 0.3s ease;
            box-shadow: 0 5px 15px rgba(255, 165, 2, 0.3);
        }

        .interrupt-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 8px 20px rgba(255, 165, 2, 0.4);
        }

        .interrupt-btn:disabled {
            background: #ccc;
            cursor: not-allowed;
            transform: none;
            box-shadow: none;
        }

        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }

        .status {
            font-size: 1.2em;
            margin: 20px 0;
            min-height: 30px;
            color: #555;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 10px;
        }

        .status.active {
            color: #2ed573;
            font-weight: bold;
        }

        .status.listening {
            color: #5352ed;
            font-weight: bold;
        }

        .status.speaking {
            color: #ff4757;
            font-weight: bold;
        }

        .transcripts {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin: 30px 0;
        }

        .transcript-section {
            background: #f8f9fa;
            border-radius: 10px;
            padding: 20px;
            text-align: left;
            min-height: 150px;
        }

        .transcript-section h3 {
            color: #333;
            margin-bottom: 15px;
            font-size: 1.1em;
            text-align: center;
        }

        .transcript-content {
            background: white;
            border-radius: 8px;
            padding: 15px;
            border-left: 4px solid #667eea;
            font-style: italic;
            color: #555;
            min-height: 80px;
            max-height: 200px;
            overflow-y: auto;
            white-space: pre-wrap;
        }

        .user-transcript {
            border-left-color: #2ed573;
        }

        .ai-transcript {
            border-left-color: #ff6b6b;
        }

        .voice-indicator {
            display: inline-flex;
            align-items: center;
            gap: 5px;
        }

        .voice-wave {
            width: 4px;
            height: 20px;
            background: currentColor;
            animation: wave 1s infinite;
            border-radius: 2px;
        }

        .voice-wave:nth-child(2) { animation-delay: 0.1s; }
        .voice-wave:nth-child(3) { animation-delay: 0.2s; }
        .voice-wave:nth-child(4) { animation-delay: 0.3s; }

        @keyframes wave {
            0%, 100% { transform: scaleY(1); }
            50% { transform: scaleY(0.3); }
        }

        .connection-status {
            position: absolute;
            top: 20px;
            right: 20px;
            padding: 8px 15px;
            border-radius: 20px;
            font-size: 0.9em;
            font-weight: bold;
        }

        .connection-status.connected {
            background: #2ed573;
            color: white;
        }

        .connection-status.disconnected {
            background: #ff4757;
            color: white;
        }

        .audio-visualizer {
            width: 100%;
            height: 60px;
            margin: 20px 0;
            background: #f0f0f0;
            border-radius: 10px;
            position: relative;
            overflow: hidden;
        }

        .error-message {
            background: #ff4757;
            color: white;
            padding: 15px;
            border-radius: 10px;
            margin: 20px 0;
            display: none;
        }

        @media (max-width: 768px) {
            .transcripts {
                grid-template-columns: 1fr;
            }
            
            .voice-controls {
                flex-direction: column;
                gap: 15px;
            }
        }
    </style>
</head>
<body>
    <div class="connection-status" id="connectionStatus">Connecting...</div>
    
    <div class="container">
        <h1>üéôÔ∏è Real-Time AI Voice Chat</h1>
        <p class="subtitle">Speak naturally - AI responds in real-time! You can interrupt anytime.</p>

        <div class="voice-controls">
            <button id="toggleBtn" class="record-btn" title="Toggle voice chat">üé§</button>
            <button id="interruptBtn" class="interrupt-btn" disabled>‚èπÔ∏è Interrupt</button>
        </div>

        <div id="status" class="status">Click the microphone to start real-time chat</div>

        <div class="audio-visualizer" id="audioVisualizer"></div>

        <div class="transcripts">
            <div class="transcript-section">
                <h3>üë§ You're saying:</h3>
                <div id="userTranscript" class="transcript-content user-transcript"></div>
            </div>
            <div class="transcript-section">
                <h3>ü§ñ AI is saying:</h3>
                <div id="aiTranscript" class="transcript-content ai-transcript"></div>
            </div>
        </div>

        <div id="errorMessage" class="error-message"></div>
    </div>

    <script>
        class RealTimeVoiceChat {
            constructor() {
                this.ws = null;
                this.mediaRecorder = null;
                this.audioContext = null;
                this.isActive = false;
                this.isConnected = false;
                this.audioChunks = [];
                
                this.initializeElements();
                this.connectWebSocket();
            }

            initializeElements() {
                this.toggleBtn = document.getElementById('toggleBtn');
                this.interruptBtn = document.getElementById('interruptBtn');
                this.status = document.getElementById('status');
                this.userTranscript = document.getElementById('userTranscript');
                this.aiTranscript = document.getElementById('aiTranscript');
                this.connectionStatus = document.getElementById('connectionStatus');
                this.errorMessage = document.getElementById('errorMessage');

                this.toggleBtn.addEventListener('click', () => this.toggleVoiceChat());
                this.interruptBtn.addEventListener('click', () => this.interrupt());
            }

            connectWebSocket() {
                const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
                const wsUrl = `${protocol}//${window.location.host}/ws/realtime-voice/`;
                
                this.ws = new WebSocket(wsUrl);
                
                this.ws.onopen = () => {
                    this.isConnected = true;
                    this.updateConnectionStatus('Connected', 'connected');
                    this.updateStatus('Ready to chat! Click microphone to start.');
                };

                this.ws.onmessage = (event) => {
                    const data = JSON.parse(event.data);
                    this.handleWebSocketMessage(data);
                };

                this.ws.onclose = () => {
                    this.isConnected = false;
                    this.updateConnectionStatus('Disconnected', 'disconnected');
                    this.updateStatus('Connection lost. Refresh to reconnect.');
                };

                this.ws.onerror = (error) => {
                    console.error('WebSocket error:', error);
                    this.showError('Connection error. Please refresh and try again.');
                };
            }

            async toggleVoiceChat() {
                if (!this.isActive) {
                    await this.startVoiceChat();
                } else {
                    this.stopVoiceChat();
                }
            }

            async startVoiceChat() {
                try {
                    // Request microphone access
                    const stream = await navigator.mediaDevices.getUserMedia({ 
                        audio: {
                            sampleRate: 16000,
                            channelCount: 1,
                            echoCancellation: true,
                            noiseSuppression: true
                        } 
                    });

                    this.setupAudioRecording(stream);
                    this.isActive = true;
                    this.toggleBtn.classList.add('active');
                    this.toggleBtn.textContent = 'üî¥';
                    this.interruptBtn.disabled = false;
                    this.updateStatus('Listening...', 'listening');

                } catch (error) {
                    console.error('Error starting voice chat:', error);
                    this.showError('Could not access microphone. Please allow microphone access.');
                }
            }

            setupAudioRecording(stream) {
                this.audioContext = new AudioContext({ sampleRate: 16000 });
                const source = this.audioContext.createMediaStreamSource(stream);
                
                // Create a script processor for real-time audio processing
                const processor = this.audioContext.createScriptProcessor(4096, 1, 1);
                
                processor.onaudioprocess = (event) => {
                    if (this.isActive && this.ws && this.ws.readyState === WebSocket.OPEN) {
                        const inputData = event.inputBuffer.getChannelData(0);
                        
                        // Convert float32 to int16 PCM
                        const pcmData = new Int16Array(inputData.length);
                        for (let i = 0; i < inputData.length; i++) {
                            pcmData[i] = Math.max(-32768, Math.min(32767, inputData[i] * 32768));
                        }
                        
                        // Convert to base64 and send
                        const base64Audio = btoa(String.fromCharCode(...new Uint8Array(pcmData.buffer)));
                        this.ws.send(JSON.stringify({
                            type: 'audio_data',
                            audio: base64Audio
                        }));
                    }
                };

                source.connect(processor);
                processor.connect(this.audioContext.destination);
                this.processor = processor;
            }

            stopVoiceChat() {
                this.isActive = false;
                this.toggleBtn.classList.remove('active');
                this.toggleBtn.textContent = 'üé§';
                this.interruptBtn.disabled = true;
                this.updateStatus('Voice chat stopped.');

                if (this.processor) {
                    this.processor.disconnect();
                }
                if (this.audioContext) {
                    this.audioContext.close();
                }
            }

            interrupt() {
                if (this.ws && this.ws.readyState === WebSocket.OPEN) {
                    this.ws.send(JSON.stringify({
                        type: 'interrupt'
                    }));
                    this.updateStatus('Interrupting AI response...', 'listening');
                }
            }

            handleWebSocketMessage(data) {
                switch (data.type) {
                    case 'audio_delta':
                        this.playAudioDelta(data.audio);
                        break;
                    
                    case 'ai_transcript_delta':
                        this.appendAiTranscript(data.text);
                        break;
                    
                    case 'user_transcript':
                        this.setUserTranscript(data.text);
                        break;
                    
                    case 'user_speech_started':
                        this.updateStatus('You are speaking...', 'speaking');
                        break;
                    
                    case 'user_speech_stopped':
                        this.updateStatus('Processing your speech...', 'listening');
                        break;
                    
                    case 'response_done':
                        this.updateStatus('AI finished speaking. Continue the conversation!', 'active');
                        break;
                    
                    case 'error':
                        this.showError(data.message);
                        break;
                }
            }

            playAudioDelta(base64Audio) {
                // Convert base64 to audio and play
                try {
                    const binaryString = atob(base64Audio);
                    const bytes = new Uint8Array(binaryString.length);
                    for (let i = 0; i < binaryString.length; i++) {
                        bytes[i] = binaryString.charCodeAt(i);
                    }
                    
                    // For real-time audio playback, you'd typically use Web Audio API
                    // This is a simplified version - you might want to use a proper audio streaming library
                    this.updateStatus('AI is speaking...', 'speaking');
                } catch (error) {
                    console.error('Error playing audio:', error);
                }
            }

            appendAiTranscript(text) {
                this.aiTranscript.textContent += text;
                this.aiTranscript.scrollTop = this.aiTranscript.scrollHeight;
            }

            setUserTranscript(text) {
                this.userTranscript.textContent = text;
                this.userTranscript.scrollTop = this.userTranscript.scrollHeight;
            }

            updateStatus(message, type = '') {
                this.status.innerHTML = message;
                this.status.className = `status ${type}`;
                
                if (type === 'listening' || type === 'speaking') {
                    this.status.innerHTML += ' <div class="voice-indicator"><div class="voice-wave"></div><div class="voice-wave"></div><div class="voice-wave"></div></div>';
                }
            }

            updateConnectionStatus(message, type) {
                this.connectionStatus.textContent = message;
                this.connectionStatus.className = `connection-status ${type}`;
            }

            showError(message) {
                this.errorMessage.textContent = message;
                this.errorMessage.style.display = 'block';
                setTimeout(() => {
                    this.errorMessage.style.display = 'none';
                }, 5000);
            }
        }

        // Initialize the real-time voice chat when the page loads
        window.addEventListener('load', () => {
            new RealTimeVoiceChat();
        });
    </script>
</body>
</html> 